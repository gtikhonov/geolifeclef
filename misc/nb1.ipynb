{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243db15c-c6f9-49b3-80ce-2f2f5b1dbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import yaml\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "from typing import Optional\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "# from flux_load_data_vInf3 import flux_dataset, flux_dataloader\n",
    "# from flux_regress import RegressionModel_flux\n",
    "\n",
    "from PIL import Image\n",
    "# from flux_load_data_vInf3 import load_raster\n",
    "# from flux_load_data_vInf3 import preprocess_image\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import random\n",
    "from torcheval.metrics import R2Score\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint, RichProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchgeo.trainers import BaseTask\n",
    "\n",
    "from terratorch.models import EncoderDecoderFactory\n",
    "from terratorch.datasets import HLSBands\n",
    "from terratorch.tasks import PixelwiseRegressionTask\n",
    "from terratorch.models.pixel_wise_model import freeze_module\n",
    "from huggingface_hub import hf_hub_download\n",
    "from terratorch.models.backbones.prithvi_mae import PrithviViT\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as v2\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c294a-3fab-4ad0-86ec-48de1d552a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prithvi_terratorch(nn.Module):\n",
    "  def __init__(self, prithvi_weight, model_instance, input_size):\n",
    "    super(prithvi_terratorch, self).__init__()\n",
    "    # load checkpoint for Prithvi_global\n",
    "    self.weights_path = prithvi_weight\n",
    "    self.checkpoint = torch.load(self.weights_path)\n",
    "    self.input_size = input_size\n",
    "    self.prithvi_model = model_instance   \n",
    "    self.prithvi_model.load_state_dict(self.checkpoint, strict=False)\n",
    "\n",
    "  def freeze_encoder(self):\n",
    "    freeze_module(self.prithvi_model)\n",
    "\n",
    "  def forward(self,x,temp,loc,mask):\n",
    "    latent,_,ids_restore = self.prithvi_model.forward(x,temp,loc,mask)\n",
    "    return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d1e03-3b46-4127-913d-bdc2142418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raster(path, if_img=1, crop=None):\n",
    "  with rasterio.open(path) as src:\n",
    "    img = src.read(out_dtype=np.float32)\n",
    "    # load  selected 4 bands for Sentinnel 2 (S2)\n",
    "    if if_img==1:\n",
    "      bands=[0,1,2,3]\n",
    "      img = img[bands,:,:]\n",
    "    # img = np.where(img == NO_DATA, NO_DATA_FLOAT, img)# update our NO_DATA with -0.9999 -- chips are already scaled\n",
    "    # print(\"img size\",img.shape) \n",
    "    if crop:\n",
    "      img = img[:, -crop[0]:, -crop[1]:]\n",
    "  # print('return from load ras')\n",
    "  return img\n",
    "\n",
    "def preprocess_image(image, means, stds):        \n",
    "    # normalize image\n",
    "    means1 = means.reshape(-1,1,1)  # Mean across height and width, for each channel\n",
    "    stds1 = stds.reshape(-1,1,1)    # Std deviation across height and width, for each channel\n",
    "    normalized = ((image - means1) / stds1)\n",
    "    normalized = torch.from_numpy(normalized).to(torch.float32)\n",
    "    #normalized = torch.from_numpy(normalized.reshape(1, normalized.shape[0], 1, *normalized.shape[-2:])).to(torch.float32)\n",
    "    #print('return from norm')\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1066519-8d27-479c-920d-2c1e11928ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "  def __init__(self, dir_sentinel, dir_landsat, metadata, subset, num_classes, transform_sentinel=None, transform_landsat=None,\n",
    "              mean_sentinel=np.array([0.0]), std_sentinel=np.array([1.0])):\n",
    "    self.subset = subset\n",
    "    self.transform_sentinel = transform_sentinel\n",
    "    self.mean_sentinel = np.array(mean_sentinel)\n",
    "    self.std_sentinel = np.array(std_sentinel)\n",
    "    self.transform_landsat = transform_landsat\n",
    "    self.dir_sentinel = dir_sentinel\n",
    "    self.dir_landsat = dir_landsat\n",
    "    self.num_classes = num_classes\n",
    "    self.metadata = metadata\n",
    "    self.metadata = self.metadata.dropna(subset=\"speciesId\").reset_index(drop=True)\n",
    "    self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)\n",
    "    self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "    self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.metadata)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    survey_id = self.metadata.surveyId[idx]\n",
    "    species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n",
    "    label = torch.zeros(self.num_classes).scatter(0, torch.tensor(species_ids), torch.ones(len(species_ids)))\n",
    "\n",
    "    sample_landsat = torch.nan_to_num(torch.load(os.path.join(self.dir_landsat, f\"GLC25-PA-{self.subset}-landsat-time-series_{survey_id}_cube.pt\"), weights_only=True))\n",
    "    if self.transform_landsat:\n",
    "      sample_landsat = self.transform_landsat(sample_landsat)\n",
    "      \n",
    "    dir1, dir2 = survey_id % 100, (survey_id // 100) % 100\n",
    "    dir2_str = f\"{dir2}\" if survey_id < 10000 else f\"{dir2:02}\"\n",
    "    path_sentinel = os.path.join(self.dir_sentinel, f\"{dir1:02}\", dir2_str, f\"{survey_id}.tiff\")\n",
    "    image_sentinel = preprocess_image(load_raster(path_sentinel) / 1e4, self.mean_sentinel, self.std_sentinel)\n",
    "    sample_sentinel = torch.nan_to_num(image_sentinel)\n",
    "    if self.transform_sentinel:\n",
    "      sample_sentinel = self.transform_sentinel(sample_sentinel)\n",
    "    #TODO add transformations RandomRotation by 90 (write own?)\n",
    "    return sample_sentinel, sample_landsat, label, survey_id\n",
    "    \n",
    "class TestDataset(TrainDataset):\n",
    "  def __init__(self, dir_sentinel, dir_landsat, metadata, subset, num_classes=None, transform_sentinel=None, transform_landsat=None,\n",
    "              mean_sentinel=np.array([0.0]), std_sentinel=np.array([1.0])):\n",
    "    self.subset = subset\n",
    "    self.transform_sentinel = np.array(transform_sentinel)\n",
    "    self.mean_sentinel = np.array(mean_sentinel)\n",
    "    self.std_sentinel = np.array(std_sentinel)\n",
    "    self.transform_landsat = transform_landsat\n",
    "    self.dir_sentinel = dir_sentinel\n",
    "    self.dir_landsat = dir_landsat\n",
    "    self.metadata = metadata\n",
    "    self.num_classes = num_classes\n",
    "      \n",
    "  def __getitem__(self, idx):\n",
    "    survey_id = self.metadata.surveyId[idx]\n",
    "    sample_landsat = torch.nan_to_num(torch.load(os.path.join(self.dir_landsat, f\"GLC25-PA-{self.subset}-landsat_time_series_{survey_id}_cube.pt\"), weights_only=True))\n",
    "    if self.transform_landsat:\n",
    "      sample_landsat = self.transform_landsat(sample_landsat)\n",
    "      \n",
    "    dir1, dir2 = survey_id % 100, (survey_id // 100) % 100\n",
    "    dir2_str = f\"{dir2}\" if survey_id < 10000 else f\"{dir2:02}\"\n",
    "    path_sentinel = os.path.join(self.dir_sentinel, f\"{dir1:02}\", dir2_str, f\"{survey_id}.tiff\")\n",
    "    image_sentinel = preprocess_image(load_raster(path_sentinel) / 1e4, self.mean_sentinel, self.std_sentinel)\n",
    "    sample_sentinel = torch.nan_to_num(image_sentinel)\n",
    "    if self.transform_landsat:\n",
    "      sample_landsat = self.transform_landsat(sample_landsat)\n",
    "    return sample_sentinel, sample_landsat, survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb338a9-b443-4fe0-974d-b542f9a25037",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 11255\n",
    "mean_sentinel = [0.1]\n",
    "std_sentinel = [0.13]\n",
    "transform_landsat = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    # v2.RandomRotation(180)\n",
    "])\n",
    "\n",
    "transform_sentinel = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    # v2.RandomRotation(180)\n",
    "])\n",
    "\n",
    "\n",
    "# Load Training metadata\n",
    "path_data = \"/home/gt/DATA/geolifeclef-2025\"\n",
    "train_path_sentinel = os.path.join(path_data, \"SatelitePatches/PA-train\")\n",
    "train_path_landsat = os.path.join(path_data, \"SateliteTimeSeries-Landsat/cubes/PA-train\")\n",
    "train_metadata_path = os.path.join(path_data, \"GLC25_PA_metadata_train.csv\")\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "train_dataset = TrainDataset(train_path_sentinel, train_path_landsat, train_metadata, subset=\"train\", num_classes=num_classes, transform_sentinel=transform_sentinel,\n",
    "                            mean_sentinel=mean_sentinel, std_sentinel=std_sentinel)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print(train_dataset[0][0].shape)\n",
    "plt.figure(figsize=[12,4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_dataset[0][0].flatten())\n",
    "plt.title(\"[%.3f | %.3f]\" % (np.min(train_dataset[0][0].numpy()), np.max(train_dataset[0][0].numpy())))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(torch.permute(train_dataset[0][0][:3], [1,2,0]))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Load Test metadata\n",
    "test_path_sentinel = os.path.join(path_data, \"SatelitePatches/PA-test\")\n",
    "test_path_landsat = os.path.join(path_data, \"SateliteTimeSeries-Landsat/cubes/PA-test\")\n",
    "test_metadata_path = os.path.join(path_data, \"GLC25_PA_metadata_test.csv\")\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "test_dataset = TestDataset(test_path_sentinel, test_path_landsat, test_metadata, subset=\"test\", transform_sentinel=None,\n",
    "                          mean_sentinel=mean_sentinel, std_sentinel=std_sentinel)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(test_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630e18a-121f-4d1e-8603-6c2813d61bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = [1,16,16]\n",
    "n_frame = 1\n",
    "n_channel = 4\n",
    "embed_dim = 1024\n",
    "decoder_depth = 8\n",
    "num_heads = 16\n",
    "mlp_ratio = 4\n",
    "head_dropout = 0.0\n",
    "      \n",
    "# ### Creating an instance of our custom model used to estimate the carbon flux problem. \n",
    "path_prithvi = \"/home/gt/gdrive/codes_misc/prithvi/carbon_flux\"\n",
    "wt_file = os.path.join(path_prithvi, \"Prithvi_EO_V2_300M_TL.pt\")\n",
    "if not os.path.isfile(wt_file):\n",
    "  hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-EO-2.0-300M-TL\", filename=\"Prithvi_EO_V2_300M_TL.pt\", local_dir=path_prithvi)\n",
    "\n",
    "prithvi_instance = PrithviViT(\n",
    "        patch_size=patch_size,\n",
    "        num_frames=n_frame,\n",
    "        in_chans=n_channel,\n",
    "        embed_dim=embed_dim,\n",
    "        decoder_depth=decoder_depth,\n",
    "        num_heads=num_heads,\n",
    "        mlp_ratio=mlp_ratio,\n",
    "        head_dropout=head_dropout,\n",
    "        backbone_input_size=[1,64,64],\n",
    "        encoder_only=False,\n",
    "        padding=True,\n",
    ")\n",
    "prithvi_model = prithvi_terratorch(wt_file, prithvi_instance, [1,64,64])\n",
    "prithvi_model.freeze_encoder()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "prithvi_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c86f22-7a47-4eba-ad26-3c6670322c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed) # Set seed for Python's built-in random number generator\n",
    "    np.random.seed(seed) # Set seed for numpy\n",
    "    if torch.cuda.is_available(): # Set seed for CUDA if available\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # Set cuDNN's random number generator seed for deterministic behavior\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e0417-17ab-4593-869f-469ded1c4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, input_dim=[17,1024], hidden_dim=256, output_dim=128):\n",
    "        super(SimpleDecoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim[1], hidden_dim) # 1024 to 256; shape 17x1024 to 10x256\n",
    "        self.hidden_dim_flattened=input_dim[0] * hidden_dim #17 is feature dim+ class token in MAE; 17x256 to 4352\n",
    "        self.fc2 = nn.Linear(self.hidden_dim_flattened, output_dim) # 4352 to 128\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x)) #shape 17x1024 to 17x256 ORG\n",
    "        x = torch.reshape(x,(x.shape[0], x.shape[1]*x.shape[2])) #17x256 to 4352 \n",
    "        x = self.fc2(x) # 4352 to 128 Output shape \n",
    "        return x\n",
    "\n",
    "class ModifiedPrithvi(nn.Module):\n",
    "    def __init__(self, num_classes, prithvi_model):\n",
    "        super(ModifiedPrithvi, self).__init__()\n",
    "        self.prithvi_model = prithvi_model\n",
    "        self.decoder = SimpleDecoder(input_dim=[17,1024], hidden_dim=256, output_dim=128)\n",
    "        self.fc_final = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prithvi_model(x, None, None, torch.tensor(0, device=device))\n",
    "        x = self.decoder(x)\n",
    "        x = self.fc_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886a776-5706-43bf-b7b7-a211945ac844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cuda is available\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "num_classes = 11255 # Number of all unique classes within the PO and PA data.\n",
    "model = ModifiedPrithvi(num_classes, prithvi_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e1bbf-af8c-4ce5-9643-607c23214211",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = [train_dataset[i][0] for i in range(10)]\n",
    "img_batch = torch.stack(img_array)[:,:,None,:,:] / 1000\n",
    "prithvi_res = prithvi_model.forward(img_batch.to(device), None, None, torch.tensor(0, device=device))\n",
    "print(prithvi_res.to(device).shape)\n",
    "model_res = model.forward(img_batch.to(device))\n",
    "print(model_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca858ca8-f17f-4dd9-927f-8e2c2e055929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "#summary(model, (4, 1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f9946-b890-4abb-b97e-f27306b719cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 40\n",
    "positive_weigh_factor = 1.0\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c668b6-76d0-48ff-94e5-16a50e1183e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data_sentinel, data_landsat, targets, _) in tqdm.tqdm(enumerate(train_loader), total=len(train_loader), leave=False):\n",
    "        data_sentinel = data.to(device)[:,:,None,:,:]\n",
    "        data_landsat = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_sentinel)\n",
    "        pos_weight = targets * positive_weigh_factor  # All positive weights are equal to 10\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % 175 == 0:\n",
    "        #     print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "    scheduler.step()\n",
    "    print(\"Scheduler:\",scheduler.state_dict())\n",
    "\n",
    "# Save the trained model\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"prithvi-base-frozen.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446cbd61-c261-45f9-882c-3c5132f22d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    surveys = []\n",
    "    top_k_indices = None\n",
    "    for data, lonlat, surveyID in tqdm.tqdm(test_loader, total=len(test_loader)):\n",
    "        data = data.to(device)[:,:,None,:,:]\n",
    "        outputs = model(data)\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "        # Sellect top-25 values as predictions\n",
    "        top_25 = np.argsort(-predictions, axis=1)[:, :25] \n",
    "        if top_k_indices is None:\n",
    "            top_k_indices = top_25\n",
    "        else:\n",
    "            top_k_indices = np.concatenate((top_k_indices, top_25), axis=0)\n",
    "\n",
    "        surveys.extend(surveyID.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669b964-2023-4176-a26d-6dfe303e2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_k_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(\"submission_prithvi.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a60812-a063-4ee4-8fa4-aa22e8ddc31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
