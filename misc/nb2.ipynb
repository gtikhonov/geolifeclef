{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243db15c-c6f9-49b3-80ce-2f2f5b1dbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as v2\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchsummary import summary\n",
    "\n",
    "from terratorch.models.pixel_wise_model import freeze_module\n",
    "from huggingface_hub import hf_hub_download\n",
    "from terratorch.models.backbones.prithvi_mae import PrithviViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c86f22-7a47-4eba-ad26-3c6670322c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed) # Set seed for Python's built-in random number generator\n",
    "    np.random.seed(seed) # Set seed for numpy\n",
    "    if torch.cuda.is_available(): # Set seed for CUDA if available\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # Set cuDNN's random number generator seed for deterministic behavior\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c294a-3fab-4ad0-86ec-48de1d552a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prithvi_terratorch(nn.Module):\n",
    "  def __init__(self, prithvi_weight, model_instance, input_size):\n",
    "    super(prithvi_terratorch, self).__init__()\n",
    "    # load checkpoint for Prithvi_global\n",
    "    self.weights_path = prithvi_weight\n",
    "    self.checkpoint = torch.load(self.weights_path)\n",
    "    self.input_size = input_size\n",
    "    self.prithvi_model = model_instance   \n",
    "    self.prithvi_model.load_state_dict(self.checkpoint, strict=False)\n",
    "\n",
    "  def freeze_encoder(self):\n",
    "    freeze_module(self.prithvi_model)\n",
    "\n",
    "  def forward(self,x,temp,loc,mask):\n",
    "    latent,_,ids_restore = self.prithvi_model.forward(x,temp,loc,mask)\n",
    "    return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d1e03-3b46-4127-913d-bdc2142418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raster(path, if_img=1, crop=None):\n",
    "  with rasterio.open(path) as src:\n",
    "    img = src.read(out_dtype=np.float32)\n",
    "    # load  selected 4 bands for Sentinnel 2 (S2)\n",
    "    if if_img==1:\n",
    "      bands=[0,1,2,3]\n",
    "      img = img[bands,:,:]\n",
    "    # img = np.where(img == NO_DATA, NO_DATA_FLOAT, img)# update our NO_DATA with -0.9999 -- chips are already scaled\n",
    "    # print(\"img size\",img.shape) \n",
    "    if crop:\n",
    "      img = img[:, -crop[0]:, -crop[1]:]\n",
    "  # print('return from load ras')\n",
    "  return img\n",
    "\n",
    "def preprocess_image(image, means, stds):        \n",
    "    # normalize image\n",
    "    means1 = means.reshape(-1,1,1)  # Mean across height and width, for each channel\n",
    "    stds1 = stds.reshape(-1,1,1)    # Std deviation across height and width, for each channel\n",
    "    normalized = ((image - means1) / stds1)\n",
    "    normalized = torch.from_numpy(normalized).to(torch.float32)\n",
    "    #normalized = torch.from_numpy(normalized.reshape(1, normalized.shape[0], 1, *normalized.shape[-2:])).to(torch.float32)\n",
    "    #print('return from norm')\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1066519-8d27-479c-920d-2c1e11928ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dir_sentinel, dir_landsat, dir_bioclim, metadata, subset, num_classes=None, transform_sentinel=None, transform_landsat=None,\n",
    "                 mean_sentinel=np.array([0.0]), std_sentinel=np.array([1.0])):\n",
    "        self.subset = subset\n",
    "        self.transform_sentinel = transform_sentinel\n",
    "        self.mean_sentinel = np.array(mean_sentinel)\n",
    "        self.std_sentinel = np.array(std_sentinel)\n",
    "        self.transform_landsat = transform_landsat\n",
    "        self.dir_sentinel = dir_sentinel\n",
    "        self.dir_landsat = dir_landsat\n",
    "        self.dir_bioclim = dir_bioclim\n",
    "        self.metadata = metadata\n",
    "        self.num_classes = num_classes\n",
    "        if self.subset == \"test\":\n",
    "            self.landsat_file_sep = \"_\"\n",
    "        elif self.subset == \"train\":\n",
    "            self.landsat_file_sep = \"-\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        lonlat = torch.tensor(self.metadata.loc[idx, [\"lon\",\"lat\"]].values.astype(np.float32))\n",
    "        path_landsat = os.path.join(self.dir_landsat, f\"GLC25-PA-{self.subset}-landsat{self.landsat_file_sep}time{self.landsat_file_sep}series_{survey_id}_cube.pt\")\n",
    "        sample_landsat = torch.nan_to_num(torch.load(path_landsat, weights_only=True)[:,:,:landsat_year_len])\n",
    "        if self.transform_landsat:\n",
    "            sample_landsat = self.transform_landsat(sample_landsat)\n",
    "        path_bioclim = os.path.join(self.dir_bioclim, f\"GLC25-PA-{self.subset}-bioclimatic_monthly_{survey_id}_cube.pt\")\n",
    "        sample_bioclim = torch.nan_to_num(torch.load(path_bioclim, weights_only=True))\n",
    "        #print(sample_bioclim.shape)\n",
    "        tmp1 = torch.reshape(sample_bioclim, [4,-1])\n",
    "        tmp2 = torch.reshape(torch.cat([tmp1[:,:1], tmp1[:,:bioclim_month_len]], axis=-1), [4,landsat_year_len,4,3])\n",
    "        sample_bioclim_new = torch.permute(torch.mean(tmp2, -1), [0,2,1])[:2] \n",
    "        sample_bioclim_new = (sample_bioclim_new - np.array([0,2730])[:,None,None]) / np.array([5000,300])[:,None,None]\n",
    "        #print(sample_bioclim_new.shape)\n",
    "        sample_landsat = torch.cat([sample_landsat, sample_bioclim_new], 0)\n",
    "        #print(sample_landsat.shape)\n",
    "        dir1, dir2 = str(survey_id)[-2:], str(survey_id)[-4:-2]        \n",
    "        path_sentinel = os.path.join(self.dir_sentinel, dir1, dir2, f\"{survey_id}.tiff\")\n",
    "        image_sentinel = preprocess_image(load_raster(path_sentinel) / 1e4, self.mean_sentinel, self.std_sentinel)\n",
    "        sample_sentinel = torch.nan_to_num(image_sentinel)\n",
    "        if self.transform_sentinel:\n",
    "            sample_sentinel = self.transform_sentinel(sample_sentinel)\n",
    "        return sample_sentinel, sample_landsat, lonlat, survey_id\n",
    "\n",
    "class TrainDataset(TestDataset):\n",
    "  def __init__(self, dir_sentinel, dir_landsat, dir_bioclim, metadata, subset, num_classes, transform_sentinel=None, transform_landsat=None,\n",
    "              mean_sentinel=np.array([0.0]), std_sentinel=np.array([1.0])):\n",
    "    super(TrainDataset, self).__init__(dir_sentinel, dir_landsat, dir_bioclim, metadata, subset, num_classes, transform_sentinel, transform_landsat,\n",
    "              mean_sentinel, std_sentinel)\n",
    "    self.metadata = self.metadata.dropna(subset=\"speciesId\").reset_index(drop=True)\n",
    "    self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)\n",
    "    self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "    self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    sample_sentinel, sample_landsat, lonlat, survey_id = super(TrainDataset, self).__getitem__(idx)\n",
    "    species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n",
    "    label = torch.zeros(self.num_classes).scatter(0, torch.tensor(species_ids), torch.ones(len(species_ids)))\n",
    "    return sample_sentinel, sample_landsat, lonlat, label, survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb338a9-b443-4fe0-974d-b542f9a25037",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 4\n",
    "num_classes = 11255\n",
    "landsat_year_len = 18\n",
    "bioclim_month_len = landsat_year_len*12-1\n",
    "mean_sentinel = [0.1]\n",
    "std_sentinel = [0.13]\n",
    "validation_prop = 0.1\n",
    "transform_landsat = v2.Compose([\n",
    "    # v2.RandomRotation(180)\n",
    "])\n",
    "\n",
    "transform_sentinel = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomRotation(180)\n",
    "])\n",
    "\n",
    "# Load Training metadata\n",
    "set_seed(42)\n",
    "path_data = \"/home/gt/DATA/geolifeclef-2025\"\n",
    "train_path_sentinel = os.path.join(path_data, \"SatelitePatches/PA-train\")\n",
    "train_path_landsat = os.path.join(path_data, \"SateliteTimeSeries-Landsat/cubes/PA-train\")\n",
    "train_path_bioclim = os.path.join(path_data, \"BioclimTimeSeries/cubes/PA-train\")\n",
    "train_metadata = pd.read_csv(os.path.join(path_data, \"GLC25_PA_metadata_train.csv\"))\n",
    "train_metadata_groups = list(train_metadata.groupby(\"surveyId\"))\n",
    "#val_ind = np.sort(np.random.choice(train_metadata.shape[0], np.round(train_metadata.shape[0] / 10).astype(int), replace=False))\n",
    "val_ind = np.sort(train_metadata.surveyId.drop_duplicates().sample(frac=validation_prop).values)\n",
    "#val_row = train_metadata.surveyId.isin(val_ind)\n",
    "#val_metadata = train_metadata.loc[val_row]\n",
    "#train_metadata = train_metadata.loc[~val_row]\n",
    "train_metadata, val_metadata = [x for _, x in train_metadata.groupby(train_metadata.surveyId.isin(val_ind))]\n",
    "train_dataset = TrainDataset(train_path_sentinel, train_path_landsat, train_path_bioclim, train_metadata, subset=\"train\", num_classes=num_classes, transform_sentinel=transform_sentinel,\n",
    "                            mean_sentinel=mean_sentinel, std_sentinel=std_sentinel)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dataset = TrainDataset(train_path_sentinel, train_path_landsat, train_path_bioclim, val_metadata, subset=\"train\", num_classes=num_classes, transform_sentinel=transform_sentinel,\n",
    "                            mean_sentinel=mean_sentinel, std_sentinel=std_sentinel)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "print(\"train size: \", len(train_dataset), \" | validation size: \", len(val_dataset))\n",
    "print(train_dataset[0][0].shape)\n",
    "plt.figure(figsize=[12,4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_dataset[0][0].flatten())\n",
    "plt.title(\"[%.3f | %.3f]\" % (np.min(train_dataset[0][0].numpy()), np.max(train_dataset[0][0].numpy())))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(torch.permute(train_dataset[0][0][:3], [1,2,0]))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Load Test metadata\n",
    "test_path_sentinel = os.path.join(path_data, \"SatelitePatches/PA-test\")\n",
    "test_path_landsat = os.path.join(path_data, \"SateliteTimeSeries-Landsat/cubes/PA-test\")\n",
    "test_path_bioclim = os.path.join(path_data, \"BioclimTimeSeries/cubes/PA-test\")\n",
    "test_metadata = pd.read_csv(os.path.join(path_data, \"GLC25_PA_metadata_test.csv\"))\n",
    "test_dataset = TestDataset(test_path_sentinel, test_path_landsat, test_path_bioclim, test_metadata, subset=\"test\", transform_sentinel=None,\n",
    "                          mean_sentinel=mean_sentinel, std_sentinel=std_sentinel)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "print(test_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbee21-5853-4a59-923c-9410028c4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, squeeze=False, sharey=\"all\", figsize=[18,8])\n",
    "id_im = 5*6\n",
    "for idr, axr in enumerate(axes):\n",
    "    for idc, ax in enumerate(axr):\n",
    "        for ch in range(6, train_dataset[id_im][1].shape[0]):\n",
    "            ax.plot(torch.transpose(train_dataset[id_im][1][ch], 1,0).numpy().reshape(-1))\n",
    "        id_im += 1\n",
    "        ax.set_title(\"surveyId %d\"%train_dataset[id_im][4])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fd5d4-f4f2-435f-aeb5-5086cf65c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(os.path.join(path_data, \"GLC25_PA_metadata_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24d152-fce8-4236-b340-b04e70f842f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata.speciesId.drop_duplicates().sort_values()\n",
    "prev_min = 10\n",
    "train_metadata.value_counts(\"speciesId\").sort_index().pipe(lambda x: x[x>=prev_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0448d48-47dc-4776-b0c4-6fd1946c2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0][1].shape)\n",
    "#val = np.zeros([len(train_dataset)])\n",
    "#for i, d in enumerate(tqdm.tqdm(train_dataset)):\n",
    "#    val[i] = torch.sum(torch.sum(torch.reshape(torch.permute(d[1], [0,2,1]), [6, -1]), -2) == 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf81dff-d489-4905-acbf-b35ef9db48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(val[val>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630e18a-121f-4d1e-8603-6c2813d61bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = [1,16,16]\n",
    "n_frame = 1\n",
    "n_channel = 4\n",
    "embed_dim = 1024\n",
    "decoder_depth = 8\n",
    "num_heads = 16\n",
    "mlp_ratio = 4\n",
    "head_dropout = 0.0\n",
    "      \n",
    "path_prithvi = \"/home/gt/gdrive/codes_misc/prithvi/carbon_flux\"\n",
    "wt_file = os.path.join(path_prithvi, \"Prithvi_EO_V2_300M_TL.pt\")\n",
    "if not os.path.isfile(wt_file):\n",
    "  hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-EO-2.0-300M-TL\", filename=\"Prithvi_EO_V2_300M_TL.pt\", local_dir=path_prithvi)\n",
    "\n",
    "prithvi_instance = PrithviViT(\n",
    "        patch_size=patch_size,\n",
    "        num_frames=n_frame,\n",
    "        in_chans=n_channel,\n",
    "        embed_dim=embed_dim,\n",
    "        decoder_depth=decoder_depth,\n",
    "        num_heads=num_heads,\n",
    "        mlp_ratio=mlp_ratio,\n",
    "        head_dropout=head_dropout,\n",
    "        backbone_input_size=[1,64,64],\n",
    "        encoder_only=False,\n",
    "        padding=True,\n",
    ")\n",
    "prithvi_model = prithvi_terratorch(wt_file, prithvi_instance, [1,64,64])\n",
    "prithvi_model.freeze_encoder()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "prithvi_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e0417-17ab-4593-869f-469ded1c4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        self.norm_input = nn.LayerNorm([8,4,18])\n",
    "        self.resnet18 = models.resnet18(weights=None)\n",
    "        # We have to modify the first convolutional layer to accept 4 channels instead of 3\n",
    "        self.resnet18.conv1 = nn.Conv2d(6, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = nn.Identity()\n",
    "        self.ln = nn.LayerNorm(1000)\n",
    "        #self.fc = nn.Linear(1000, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.norm_input(x)\n",
    "        x = self.resnet18(x)\n",
    "        x = self.ln(x)\n",
    "        #x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, input_dim=[17,1024], hidden_dim=256, output_dim=128):\n",
    "        super(SimpleDecoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim[1], hidden_dim) # 1024 to 256; shape 17x1024 to 10x256\n",
    "        self.hidden_dim_flattened=input_dim[0] * hidden_dim #17 is feature dim+ class token in MAE; 17x256 to 4352\n",
    "        self.fc2 = nn.Linear(self.hidden_dim_flattened, output_dim) # 4352 to 128\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x)) #shape 17x1024 to 17x256 ORG\n",
    "        x = torch.reshape(x,(x.shape[0], x.shape[1]*x.shape[2])) #17x256 to 4352 \n",
    "        x = self.fc2(x) # 4352 to 128 Output shape \n",
    "        return x\n",
    "\n",
    "class ModifiedPrithviResNet18(nn.Module):\n",
    "    def __init__(self, num_classes, prithvi_model):\n",
    "        super(ModifiedPrithviResNet18, self).__init__()\n",
    "        self.prithvi_model = prithvi_model\n",
    "        self.decoder = SimpleDecoder(input_dim=[17,1024], hidden_dim=256, output_dim=128)\n",
    "        self.landsat_part = ModifiedResNet18(num_classes)\n",
    "        self.drop_tail = nn.Dropout(0.5)\n",
    "        self.fc_tail = nn.Linear(1000 + 128, 1000 + 128)\n",
    "        self.relu_tail = nn.ReLU()\n",
    "        self.drop_last = nn.Dropout(0.5)\n",
    "        self.fc_final = nn.Linear(1000 + 128, num_classes)\n",
    "        #self.fc_final = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, sentinel, landsat, lonlat=None):\n",
    "        x = self.prithvi_model(sentinel, None, lonlat, torch.tensor(0, device=device))\n",
    "        x0 = self.decoder(x)\n",
    "        x1 = self.landsat_part(landsat)\n",
    "        x = torch.concat([x0, x1], -1)\n",
    "        x = self.drop_tail(x)\n",
    "        x = self.fc_tail(x)\n",
    "        x = self.relu_tail(x)\n",
    "        x = self.drop_last(x)\n",
    "        x = self.fc_final(x)\n",
    "        #x = self.fc_final(x1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886a776-5706-43bf-b7b7-a211945ac844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cuda is available\n",
    "set_seed(69)\n",
    "model = ModifiedPrithviResNet18(num_classes, prithvi_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca858ca8-f17f-4dd9-927f-8e2c2e055929",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet18 = ModifiedResNet18(num_classes).to(device)\n",
    "summary(resNet18, (6, 4, 18))\n",
    "\n",
    "#summary(model.landsat_part, [(4, 1, 64, 64), (6, 4, 21)])\n",
    "#list(model.fc_final.named_parameters())\n",
    "#[name for name, p in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e1bbf-af8c-4ce5-9643-607c23214211",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "sentinel_batch = torch.stack([train_dataset[i][0] for i in range(n)])[:,:,None,:,:]\n",
    "landsat_batch = torch.stack([train_dataset[i][1] for i in range(n)])\n",
    "lonlat_batch = torch.stack([train_dataset[i][2] for i in range(n)])\n",
    "prithvi_res = prithvi_model.forward(sentinel_batch.to(device), None, lonlat_batch.to(device), torch.tensor(0, device=device))\n",
    "print(prithvi_res.to(device).shape)\n",
    "model_res = model.forward(sentinel_batch.to(device), landsat_batch.to(device), lonlat_batch.to(device))\n",
    "print(model_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f9946-b890-4abb-b97e-f27306b719cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "weight_decay_tail = 1e-4\n",
    "num_epochs = 100\n",
    "positive_weigh_factor = 1.0\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "tail_weight_names = ['fc_final.weight', 'fc_tail.weight']\n",
    "last_layer_weights = [p for name, p in model.named_parameters() if any([par_tail_name in name for par_tail_name in tail_weight_names])]\n",
    "others = [p for name, p in model.named_parameters() if not any([par_tail_name in name for par_tail_name in tail_weight_names])]\n",
    "optim_dict = [{\"params\": others}, {\"params\": last_layer_weights, \"weight_decay\": weight_decay_tail}]\n",
    "optimizer = torch.optim.AdamW(optim_dict, lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e6c2c-1224-4009-b13e-e031710d1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_weight_names = ['fc_final.weight', 'fc_tail.weight']\n",
    "[name for name, p in model.named_parameters() if any([par_tail_name in name for par_tail_name in tail_weight_names])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c668b6-76d0-48ff-94e5-16a50e1183e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "model.eval()\n",
    "loss_array = np.zeros(len(val_loader))\n",
    "for batch_idx, (data_sentinel, data_landsat, data_lonlat, targets, _) in tqdm.tqdm(enumerate(val_loader), total=len(val_loader), leave=False):\n",
    "    data_sentinel = data_sentinel.to(device)[:,:,None,:,:]\n",
    "    data_landsat = data_landsat.to(device)\n",
    "    data_lonlat = data_lonlat.to(device)\n",
    "    targets = targets.to(device)\n",
    "    outputs = model(data_sentinel, data_landsat, data_lonlat)\n",
    "    pos_weight = targets * positive_weigh_factor\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss_array[batch_idx] = loss.item()\n",
    "mean_val_loss = np.mean(loss_array)\n",
    "print(f\"Epoch {0}/{num_epochs}, train loss: NA, validation loss: {mean_val_loss:.6f}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loss_array = np.zeros(len(train_loader))\n",
    "    for batch_idx, (data_sentinel, data_landsat, data_lonlat, targets, _) in tqdm.tqdm(enumerate(train_loader), total=len(train_loader), leave=False):\n",
    "        data_sentinel = data_sentinel.to(device)[:,:,None,:,:]\n",
    "        data_landsat = data_landsat.to(device)\n",
    "        data_lonlat = data_lonlat.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_sentinel, data_landsat, data_lonlat)\n",
    "        pos_weight = targets * positive_weigh_factor\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss_array[batch_idx] = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % 175 == 0:\n",
    "        #     print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "    mean_train_loss = np.mean(loss_array)\n",
    "    \n",
    "    model.eval()\n",
    "    loss_array = np.zeros(len(val_loader))\n",
    "    for batch_idx, (data_sentinel, data_landsat, data_lonlat, targets, _) in tqdm.tqdm(enumerate(val_loader), total=len(val_loader), leave=False):\n",
    "        data_sentinel = data_sentinel.to(device)[:,:,None,:,:]\n",
    "        data_landsat = data_landsat.to(device)\n",
    "        data_lonlat = data_lonlat.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(data_sentinel, data_landsat, data_lonlat)\n",
    "        pos_weight = targets * positive_weigh_factor\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss_array[batch_idx] = loss.item()\n",
    "    mean_val_loss = np.mean(loss_array)\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, train loss: {mean_train_loss:.6f}, validation loss: {mean_val_loss:.6f}\")\n",
    "    scheduler.step()\n",
    "    # print(\"Scheduler:\",scheduler.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d993a0c-23df-4ddf-83ff-bea94c46654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"prithvi-frozen-resnet18-tail2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446cbd61-c261-45f9-882c-3c5132f22d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_train_countries = (train_metadata.country.value_counts().cumsum() / test_metadata.shape[0]).index[:10].values\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    surveys = []\n",
    "    top_indices = []\n",
    "    for data_sentinel, data_landsat, data_lonlat, surveyId in tqdm.tqdm(test_loader, total=len(test_loader)):\n",
    "        data_sentinel = data_sentinel.to(device)[:,:,None,:,:]\n",
    "        data_landsat = data_landsat.to(device)\n",
    "        data_lonlat = data_lonlat.to(device)\n",
    "        outputs = model(data_sentinel, data_landsat, data_lonlat)\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "        # Sellect top-25 values as predictions\n",
    "        top_batch = np.sort(np.argsort(-predictions, axis=1)[:, :25])\n",
    "        top_batch_list = top_batch.tolist()\n",
    "        surveyId = surveyId.numpy()\n",
    "        #tmp_metadata = test_metadata.loc[test_metadata.surveyId.isin(surveyId)]\n",
    "        #tmp_metadata.set_index(\"surveyId\", inplace=True)\n",
    "        #tmp_metadata = tmp_metadata.loc[surveyId]\n",
    "        #tmp_metadata.reset_index(drop=True, inplace=True)\n",
    "        #tmp_metadata = tmp_metadata.loc[~tmp_metadata.country.isin(most_train_countries)]\n",
    "        #for i in tmp_metadata.index:\n",
    "        #    top_batch_list[i] = np.sort(train_metadata.value_counts(\"speciesId\").index[:1000].values.astype(int))\n",
    "\n",
    "        top_indices += top_batch_list\n",
    "        surveys.extend(surveyId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669b964-2023-4176-a26d-6dfe303e2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(\"submission_prithvi-frozen_resnet18_drop05_regl2e2_e12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e927bd-ef6f-40d2-ab96-af992661dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(np.sort(predictions[0,:]))[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa6812-c86e-4aae-a5fc-1ada17c7644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_metadata.country.value_counts().cumsum() / test_metadata.shape[0]).index[:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e47f00-46d4-4d68-8079-a3c4f0a6c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata.country.value_counts().cumsum() / test_metadata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8f900-8554-4fcc-a5b7-f79f453af547",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata.country.isin(most_train_countries).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ac5fd-974c-41de-b46a-6a6f02c61f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ade87-8915-48c7-99aa-f789910df5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata.loc[test_metadata.surveyId.isin(surveyID.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fbbe7-ecd1-46a1-bab1-63b1cbc093e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055bc5f4-f704-4b16-8e13-f56404177885",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8e6fe-f10c-46db-af45-a33f2e9c6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata.surveyId.isin(surveyID.numpy()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0db12a-40d3-4873-a4e1-fc69763a2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5c1fd-9223-4693-8ff9-ca6f578ad6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(train_metadata.value_counts(\"speciesId\").values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1ac57-9004-405d-9842-a07e8c6bb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(train_metadata.value_counts(\"speciesId\").index[:1000].values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83a81e-9f48-44dd-89b7-dd9d551576f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e1128-19d7-4bac-a5a4-ebc8af8326c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
